# üß† Agentic AI for Personalized Mental Health Therapy

## Multi-Modal Sentiment Analysis & Recommendation System

A comprehensive AI-powered mental health support system that combines text, voice, and video analysis to provide personalized therapeutic recommendations and crisis intervention support.

---

## üìã Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [System Architecture](#system-architecture)
- [AI Models & LLMs Used](#ai-models--llms-used)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [API Endpoints](#api-endpoints)
- [Crisis Resources](#crisis-resources)
- [Privacy & Security](#privacy--security)
- [Contributing](#contributing)
- [License](#license)

---

## üåü Overview

This system leverages multiple AI models and modalities (text, voice, video) to provide:
- **Real-time emotion detection** from facial expressions
- **Sentiment analysis** from text and voice inputs
- **Crisis detection and intervention** with immediate resource provision
- **Personalized therapeutic recommendations** based on user patterns
- **Goal tracking and progress monitoring**
- **Secure, encrypted user data storage** with user-controlled retention

---

## ‚ú® Key Features

### üéØ Core Capabilities
- **Multi-Modal Input Processing**
  - Text chat analysis
  - Voice recognition and synthesis
  - Real-time video emotion detection
  
- **Advanced AI Analysis**
  - Emotion recognition (7 emotions: happy, sad, angry, fear, surprise, disgust, neutral)
  - Sentiment analysis (positive, negative, neutral)
  - Crisis risk assessment
  - Mental health topic detection

- **Therapeutic Support**
  - CBT (Cognitive Behavioral Therapy) techniques
  - Behavioral activation strategies
  - Mindfulness exercises
  - Coping strategy recommendations

- **Privacy-First Design**
  - User-controlled data retention (1 week to 1 year)
  - End-to-end encryption
  - Local data storage
  - Anonymous or identified sessions

- **Crisis Intervention**
  - Real-time crisis detection
  - Immediate safety resource display
  - 24/7 hotline information (India-specific)
  - Automated alert system

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (index.html)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  Text Chat  ‚îÇ  ‚îÇ   Voice I/O ‚îÇ  ‚îÇ  Video Feed ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ HTTP/WebSocket
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Flask Backend (app.py)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ            Session Manager & Router                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ        ‚îÇ
         ‚ñº         ‚ñº         ‚ñº         ‚ñº        ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Text  ‚îÇ ‚îÇVoice ‚îÇ ‚îÇ Video ‚îÇ ‚îÇTherapy‚îÇ ‚îÇ Agentic ‚îÇ
    ‚îÇAnalyzer‚îÇ ‚îÇAgent ‚îÇ ‚îÇ Agent ‚îÇ ‚îÇ Agent ‚îÇ ‚îÇ System  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ
         ‚ñº         ‚ñº         ‚ñº         ‚ñº         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ           AI Models & Services                   ‚îÇ
    ‚îÇ  ‚Ä¢ HuggingFace Transformers                     ‚îÇ
    ‚îÇ  ‚Ä¢ Groq LLM API (Llama 3.3 70B)                ‚îÇ
    ‚îÇ  ‚Ä¢ Ollama (Llama 3.1 8B - Local)               ‚îÇ
    ‚îÇ  ‚Ä¢ OpenCV + FER (Emotion Detection)            ‚îÇ
    ‚îÇ  ‚Ä¢ Speech Recognition + pyttsx3                ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Encrypted Storage    ‚îÇ
              ‚îÇ  ‚Ä¢ SQLite Database     ‚îÇ
              ‚îÇ  ‚Ä¢ JSON Session Data   ‚îÇ
              ‚îÇ  ‚Ä¢ User Goals/Progress ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ü§ñ AI Models & LLMs Used

### 1. **Large Language Models (LLMs)**

#### Primary LLM - Groq API
- **File**: `therapy_agent.py`
- **Model**: `llama-3.3-70b-versatile`
- **Purpose**: Therapeutic conversation generation, empathetic responses
- **Provider**: Groq Cloud API
- **Configuration**: 
  ```python
  model = "llama-3.3-70b-versatile"
  temperature = 0.7
  max_tokens = 300
  ```

#### Fallback LLM - Ollama (Local)
- **File**: `therapy_agent.py`
- **Model**: `llama3.1:8b`
- **Purpose**: Local LLM processing when Groq is unavailable
- **Provider**: Ollama (self-hosted)
- **URL**: `http://localhost:11434`

#### Crisis-Specific LLM
- **File**: `crisis_counselling_mode.py`
- **Model**: `llama-3.3-70b-versatile` (Groq)
- **Purpose**: Crisis intervention, safety planning, de-escalation
- **Special Features**: Enhanced crisis detection, resource recommendation

---

### 2. **Emotion Detection Models**

#### Text Emotion Analysis
- **File**: `text_analyzer.py`
- **Model**: `j-hartmann/emotion-english-distilroberta-base`
- **Provider**: HuggingFace Transformers
- **Emotions Detected**: 7 classes (anger, disgust, fear, joy, neutral, sadness, surprise)
- **Architecture**: DistilRoBERTa
- **Use Case**: Analyzing emotional content in user text messages

#### Video Facial Emotion Recognition
- **File**: `video_agent.py`
- **Library**: `FER` (Facial Emotion Recognition)
- **Model**: Deep Neural Network with MTCNN face detection
- **Emotions Detected**: 7 emotions (happy, sad, angry, fear, surprise, disgust, neutral)
- **Framework**: TensorFlow/Keras backend
- **Features**:
  - Real-time face detection
  - Continuous monitoring mode
  - Confidence scoring
  - Emotion trend analysis

---

### 3. **Sentiment Analysis Models**

#### Twitter-RoBERTa Sentiment
- **File**: `text_analyzer.py`
- **Model**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
- **Provider**: HuggingFace Transformers
- **Sentiments**: Negative, Neutral, Positive
- **Architecture**: RoBERTa-base
- **Use Case**: General sentiment detection in conversations

#### VADER Sentiment (Rule-based)
- **File**: `text_analyzer.py`
- **Library**: `vaderSentiment`
- **Type**: Lexicon and rule-based sentiment analyzer
- **Output**: Compound score (-1 to +1)
- **Use Case**: Backup sentiment analysis, social media text

---

### 4. **Voice Processing Models**

#### Speech Recognition
- **File**: `voice_agent.py`
- **Library**: `SpeechRecognition`
- **Engine**: Google Speech Recognition API
- **Language**: en-US (configurable)
- **Features**: Ambient noise adjustment, timeout handling

#### Text-to-Speech
- **File**: `voice_agent.py`
- **Library**: `pyttsx3`
- **Engine**: Platform-specific (SAPI5 on Windows, nsss on macOS)
- **Voices**: Male/Female configurable
- **Settings**: Rate: 180 WPM, Volume: 0.8

---

### 5. **Computer Vision Models**

#### Face Detection
- **File**: `video_agent.py`
- **Library**: OpenCV
- **Model**: Haar Cascade Classifier (`haarcascade_frontalface_default.xml`)
- **Purpose**: Detecting faces in video frames before emotion analysis

#### Optional: MediaPipe (Future Enhancement)
- **Library**: `mediapipe`
- **Purpose**: Advanced face mesh and landmark detection
- **Status**: Installed but not actively used

---

## üìÅ Project Structure

```
health/
‚îú‚îÄ‚îÄ app.py                          # Main Flask application & API endpoints
‚îú‚îÄ‚îÄ therapy_agent.py                # LLM integration (Groq, Ollama, fallbacks)
‚îú‚îÄ‚îÄ text_analyzer.py                # Text emotion & sentiment analysis
‚îú‚îÄ‚îÄ voice_agent.py                  # Speech recognition & TTS
‚îú‚îÄ‚îÄ video_agent.py                  # Video emotion detection (FER)
‚îú‚îÄ‚îÄ agentic_therapy_system.py       # User memory, goals, progress tracking
‚îú‚îÄ‚îÄ crisis_counselling_mode.py      # Crisis detection & intervention
‚îú‚îÄ‚îÄ crisis_api.py                   # Crisis-specific API endpoints
‚îú‚îÄ‚îÄ config.json                     # Configuration file (models, APIs, settings)
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ .env                            # Environment variables (API keys)
‚îÇ
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html                  # Frontend UI (HTML/CSS/JavaScript)
‚îÇ
‚îú‚îÄ‚îÄ static/                         # Static assets (CSS, JS, images)
‚îÇ
‚îú‚îÄ‚îÄ models/                         # Cached HuggingFace models
‚îú‚îÄ‚îÄ logs/                           # Application & crisis event logs
‚îú‚îÄ‚îÄ session_data/                   # Session persistence (JSON)
‚îú‚îÄ‚îÄ privacy_records/                # User consent records
‚îú‚îÄ‚îÄ video_data/                     # Video analysis snapshots
‚îú‚îÄ‚îÄ keys/
‚îÇ   ‚îî‚îÄ‚îÄ encryption.key              # Encryption key for user data
‚îÇ
‚îú‚îÄ‚îÄ user_memory.db                  # SQLite database (encrypted user data)
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_system.py              # Integration tests
    ‚îú‚îÄ‚îÄ test_emotion_detection.py   # Emotion model tests
    ‚îú‚îÄ‚îÄ test_voice_output.py        # Voice system tests
    ‚îú‚îÄ‚îÄ test_crisis_mode.py         # Crisis detection tests
    ‚îî‚îÄ‚îÄ test_multimodal.py          # Multi-modal analysis tests
```

---

## üîÑ System Flow

### 1. **Text Analysis Flow**
```
User Input (Text)
    ‚Üì
text_analyzer.py
    ‚Üì
‚îú‚îÄ‚Üí Emotion Model (DistilRoBERTa)
‚îú‚îÄ‚Üí Sentiment Model (Twitter-RoBERTa)
‚îú‚îÄ‚Üí Crisis Keyword Detection
‚îî‚îÄ‚Üí Mental Health Topic Detection
    ‚Üì
therapy_agent.py (LLM Processing)
    ‚Üì
‚îú‚îÄ‚Üí Groq API (Llama 3.3 70B) [Primary]
‚îî‚îÄ‚Üí Ollama (Llama 3.1 8B) [Fallback]
    ‚Üì
Generated Response + Analysis
    ‚Üì
Frontend Display
```

### 2. **Voice Analysis Flow**
```
User Voice Input
    ‚Üì
voice_agent.py
    ‚Üì
Speech Recognition (Google API)
    ‚Üì
Text Transcription
    ‚Üì
[Same as Text Analysis Flow]
    ‚Üì
TTS Synthesis (pyttsx3)
    ‚Üì
Audio Output
```

### 3. **Video Analysis Flow**
```
Camera Feed
    ‚Üì
video_agent.py
    ‚Üì
OpenCV Face Detection (Haar Cascade)
    ‚Üì
FER Emotion Detection (Deep Neural Network)
    ‚Üì
‚îú‚îÄ‚Üí Dominant Emotion
‚îú‚îÄ‚Üí Confidence Score
‚îú‚îÄ‚Üí All Emotion Probabilities
‚îî‚îÄ‚Üí Therapeutic Analysis
    ‚Üì
Real-time Display + Trend Tracking
```

### 4. **Crisis Detection Flow**
```
User Input (Any Modality)
    ‚Üì
text_analyzer.py (Crisis Keywords)
    ‚Üì
Crisis Risk Score (0.0 - 1.0)
    ‚Üì
[If Score > 0.5]
    ‚Üì
crisis_counselling_mode.py
    ‚Üì
‚îú‚îÄ‚Üí Immediate Safety Resources
‚îú‚îÄ‚Üí Crisis-Specific LLM Response
‚îú‚îÄ‚Üí Hotline Information (India)
‚îî‚îÄ‚Üí Event Logging
    ‚Üì
Crisis Alert Display
```

### 5. **Agentic Memory Flow**
```
User Session
    ‚Üì
agentic_therapy_system.py
    ‚Üì
‚îú‚îÄ‚Üí Encrypt User Data (Fernet)
‚îú‚îÄ‚Üí Store in SQLite Database
‚îú‚îÄ‚Üí Track Goals & Progress
‚îú‚îÄ‚Üí Learn User Patterns
‚îî‚îÄ‚Üí Generate Personalized Insights
    ‚Üì
Proactive Check-ins & Recommendations
```

---

## üöÄ Installation

### Prerequisites
- **Python**: 3.8 - 3.11 (3.10 recommended)
- **Operating System**: Windows, macOS, or Linux
- **Camera**: Optional (for video features)
- **Microphone**: Optional (for voice features)

### Step 1: Clone Repository
```bash
git clone https://github.com/JeetInTech/Agentic-AI-for-personalized-mental-health-therapy-recommendations-via-multi-modal-sentiment-analysis.git
cd health
```

### Step 2: Create Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

**Note**: On Windows, PyAudio may require:
```bash
pip install pipwin
pipwin install pyaudio
```

### Step 4: Install Ollama (Optional - for local LLM)
Download from: https://ollama.ai/download

```bash
# Pull the model
ollama pull llama3.1:8b
```

### Step 5: Configure Environment Variables
Create a `.env` file in the project root:
```env
GROQ_API_KEY=your_groq_api_key_here
SECRET_KEY=your_secret_key_here
FLASK_ENV=development
```

Get your Groq API key from: https://console.groq.com/

### Step 6: Run the Application
```bash
python app.py
```

Access the application at: **http://localhost:5000**

---

## ‚öôÔ∏è Configuration

Edit `config.json` to customize:

```json
{
  "models": {
    "emotion_model": "j-hartmann/emotion-english-distilroberta-base",
    "sentiment_model": "cardiffnlp/twitter-roberta-base-sentiment-latest"
  },
  "llm": {
    "groq_model": "llama-3.3-70b-versatile",
    "ollama_model": "llama3.1:8b",
    "temperature": 0.7,
    "max_tokens": 300
  },
  "analysis": {
    "crisis_threshold_high": 0.8,
    "crisis_threshold_moderate": 0.5
  },
  "voice": {
    "tts_rate": 180,
    "tts_volume": 0.8,
    "language": "en-US"
  },
  "video": {
    "camera_index": 0,
    "frame_width": 640,
    "frame_height": 480,
    "analysis_interval": 1.0
  }
}
```

---

## üìñ Usage

### 1. **Starting a Session**

**Private Mode** (No memory):
- No data stored
- Each session is independent
- Maximum privacy

**Agentic Mode** (Personalized):
- Data encrypted and stored locally
- Remembers conversations and goals
- Tracks progress over time
- Personalized insights

### 2. **Text Chat**
- Type messages in the chat interface
- Receive AI-powered therapeutic responses
- View real-time emotion and sentiment analysis

### 3. **Voice Input**
- Click the microphone button
- Speak your message
- System transcribes and processes
- Optional: Enable auto-speak for voice responses

### 4. **Video Analysis**
- Click "Enable Video"
- Allow camera permissions
- System detects facial emotions in real-time
- View emotion trends over time

### 5. **Goal Tracking**
- Create therapeutic goals
- Track progress
- Receive milestone updates
- Get personalized recommendations

### 6. **Crisis Resources**
- Automatic crisis detection
- Immediate display of helpline numbers
- Coping strategies
- Safety planning resources

---

## üîå API Endpoints

### Session Management
```
POST   /api/session/new              # Create new session
POST   /api/privacy/consent/request  # Request privacy consent
POST   /api/privacy/consent/respond  # Submit consent choice
POST   /api/user/authenticate         # Authenticate returning user
```

### Chat & Analysis
```
POST   /api/chat/send                # Send message & get response
GET    /api/providers/status         # Check LLM provider status
POST   /api/analyze/text             # Analyze text only
```

### Voice
```
GET    /api/voice/status             # Check voice system status
POST   /api/voice/listen             # Start voice recognition
POST   /api/voice/speak              # Synthesize speech
```

### Video
```
GET    /api/video/status             # Check video system status
POST   /api/video/start              # Start camera
POST   /api/video/analyze            # Analyze current frame
POST   /api/video/stop               # Stop camera
GET    /api/video/stream             # Video stream endpoint
```

### Crisis
```
POST   /api/crisis/assess            # Assess crisis risk
POST   /api/crisis/escalate          # Escalate to crisis mode
GET    /api/crisis/resources         # Get crisis resources
POST   /api/crisis/safety-plan       # Generate safety plan
```

### Goals
```
POST   /api/goals/create             # Create new goal
GET    /api/goals/list               # List user goals
PUT    /api/goals/update             # Update goal progress
DELETE /api/goals/{id}               # Delete goal
```

---

## üÜò Crisis Resources (India)

### Emergency Helplines
- **KIRAN Mental Health**: 1800-599-0019 (24/7)
- **Vandrevala Foundation**: 9152987821 (24/7)
- **Emergency Services**: 112

### Additional Resources
- **Suicide Prevention Helpline**: 044-24640050
- **iCall Psychosocial Helpline**: 9152987821
- **NIMHANS Helpline**: 080-46110007

**‚ö†Ô∏è Disclaimer**: This is an AI support tool, not a replacement for professional mental health care. In case of emergency, please call 112 or visit the nearest hospital.

---

## üîí Privacy & Security

### Data Protection
- **Encryption**: AES-256 (Fernet) encryption for all user data
- **Storage**: Local SQLite database (no cloud storage)
- **Password Hashing**: PBKDF2 with SHA-256
- **Session Security**: UUID-based session tokens

### User Control
- Choose data retention period (1 week to 1 year)
- Delete account and all data anytime
- Export personal data in JSON format
- Anonymous session option available

### Logging
- Crisis events logged for safety (anonymized)
- User IDs hashed in logs
- Configurable log retention
- GDPR-compliant data handling

---

## üß™ Testing

Run tests:
```bash
# All tests
pytest

# Specific tests
python test_system.py
python test_emotion_detection.py
python test_voice_output.py
python test_crisis_mode.py
```

---

## üõ†Ô∏è Troubleshooting

### Common Issues

**1. PyAudio Installation Error (Windows)**
```bash
pip install pipwin
pipwin install pyaudio
```

**2. Camera Not Working**
- Check camera permissions in Windows Settings
- Ensure no other application is using the camera
- Try different camera_index in config.json (0, 1, 2...)

**3. Voice Recognition Not Working**
- Check microphone permissions
- Test microphone in Windows Sound settings
- Install latest audio drivers

**4. LLM Not Responding**
- Verify Groq API key in .env file
- Check internet connection for Groq API
- Ensure Ollama is running for local fallback
- Check logs for detailed error messages

**5. Models Not Downloading**
- Ensure stable internet connection
- HuggingFace models download on first run
- Check available disk space (models ~500MB-2GB)

---

## üìä Performance

### Resource Requirements
- **RAM**: Minimum 4GB, Recommended 8GB+
- **Storage**: ~5GB for models and dependencies
- **CPU**: Multi-core recommended for real-time video
- **GPU**: Optional (CUDA support for faster inference)

### Model Loading Times
- Text Models: ~5-10 seconds (first load)
- Video Models: ~10-15 seconds (first load)
- LLM Response: 2-5 seconds (Groq), 5-15 seconds (Ollama)

---

## ü§ù Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## üë• Authors

- **JeetInTech** - [GitHub Profile](https://github.com/JeetInTech)

---

## üôè Acknowledgments

- **HuggingFace** for transformer models
- **Groq** for LLM API access
- **Ollama** for local LLM deployment
- **OpenCV** for computer vision
- **FER** for facial emotion recognition
- Mental health professionals who provided guidance

---

## üìû Support

For issues, questions, or suggestions:
- GitHub Issues: [Create an Issue](https://github.com/JeetInTech/Agentic-AI-for-personalized-mental-health-therapy-recommendations-via-multi-modal-sentiment-analysis/issues)
- Email: [Your Email]

---

## üîÆ Future Enhancements

- [ ] Multi-language support
- [ ] Mobile application (React Native)
- [ ] Integration with wearable devices
- [ ] Advanced emotion trend visualization
- [ ] Therapist dashboard for monitoring
- [ ] Integration with electronic health records
- [ ] Voice emotion analysis (prosody)
- [ ] Group therapy session support

---

**‚ö†Ô∏è Important Medical Disclaimer**

This application is designed to provide supportive information and is not a substitute for professional medical advice, diagnosis, or treatment. Always seek the advice of your physician or other qualified health provider with any questions you may have regarding a mental health condition. Never disregard professional medical advice or delay in seeking it because of something you have read or learned through this application.

If you are experiencing a medical emergency, please call 112 immediately.

---

Made with ‚ù§Ô∏è for mental health awareness and support
